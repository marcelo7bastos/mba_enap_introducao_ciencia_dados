{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Aula6_PIB_GeoMunicipios_Local_v2.ipynb",
   "provenance": [],
   "include_colab_link": false
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Execução local\nEste notebook é uma adaptação do original usado no Google Colab, preparada para rodar no seu ambiente local e permitir a atualização do BigQuery.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ETL para carregar o PIB, População e o Centróide dos municípios\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Configuração do ambiente local\nimport importlib\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nREQUIRED_PACKAGES = {\n    \"pandas\": \"pandas\",\n    \"dbf\": \"dbf\",\n    \"pandas_gbq\": \"pandas-gbq\",\n    \"google.oauth2\": \"google-auth\",\n    \"google.cloud\": \"google-cloud-bigquery\",\n    \"openpyxl\": \"openpyxl\",\n}\n\nfor module_name, package_name in REQUIRED_PACKAGES.items():\n    try:\n        importlib.import_module(module_name)\n    except ImportError:\n        print(f\"Instalando pacote '{package_name}'...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n\nimport pandas as pd\nfrom pandas.io import gbq\nprint(\"Ambiente local configurado.\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Pré-processamento dos centroides dos municipios\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Solução 1 - Processamento do arquivo de banco de dados (dbf)\n\n\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nimport dbf\n\nDATA_DIR = Path.cwd()\nprint(f\"Diretório de trabalho: {DATA_DIR}\")\nprint(f\"Biblioteca 'dbf' carregada: versão {getattr(dbf, '__version__', 'desconhecida')}\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\nfrom urllib.request import urlretrieve\n\nDBF_URL = \"https://github.com/renatocol/Latitude_Longitude_Brasil/raw/master/BR_Localidades_2010.dbf\"\nDBF_PATH = Path(\"BR_Localidades_2010.dbf\")\n\nif not DBF_PATH.exists():\n    print(f\"Baixando {DBF_PATH.name}...\")\n    urlretrieve(DBF_URL, DBF_PATH)\n    print(f\"Download concluído: {DBF_PATH.resolve()}\")\nelse:\n    size = DBF_PATH.stat().st_size\n    print(f\"Arquivo {DBF_PATH.name} já existe ({size:,} bytes).\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pathlib import Path\n\nprint(\"Arquivos no diretório atual:\")\nfor entry in sorted(Path.cwd().iterdir()):\n    if entry.is_file():\n        print(f\"- {entry.name} ({entry.stat().st_size:,} bytes)\")\n    else:\n        print(f\"- {entry.name}/\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import dbf\nimport pandas as pd\nfrom pathlib import Path\n\nDBF_PATH = Path(\"BR_Localidades_2010.dbf\")\nif not DBF_PATH.exists():\n    raise FileNotFoundError(\"Arquivo BR_Localidades_2010.dbf não encontrado. Execute a célula de download antes.\")\n\ntable = dbf.Table(str(DBF_PATH))\ntable.open(dbf.READ_ONLY)\ntry:\n    df = pd.DataFrame(table)\nfinally:\n    table.close()\n\nprint(f\"Registros carregados: {df.shape[0]} linhas x {df.shape[1]} colunas\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df.head()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Equivalente SQL: select col9 as cod_ibge, col16 as categoria, col18 as long, col19 as lat from df\ndf_geo = df[[9,16,18,19]].rename(columns={9:\"cod_ibge\", 16:\"categoria\", 18:\"long\", 19:\"lat\"})\ndf_geo['cod_ibge'] = df_geo['cod_ibge'].str.strip()\ndf_geo['categoria'] = df_geo['categoria'].str.strip()\ndf_geo = df_geo[df_geo['categoria']=='CIDADE']\ndf_geo.info()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df_geo['lat_long'] = df_geo[['lat','long']].apply(lambda x: f\"{str(x['lat']).replace(',','.')},{str(x['long']).replace(',','.')}\", axis=1)\ndf_geo.head()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "cat = 'CIDADE      '\ncat.strip()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Solução 2 - Converter o arquivo dbf para xlsx usando o excel. Processar o arquivo xlsx com o pandas\n#### Vantagem: mais rápido do que o pandas processar o arquivo dbf.\n#### URL do arquivo exportado para xlsx https://github.com/alexlopespereira/mba_enap/raw/refs/heads/main/data/originais/centroide_municipios/BR_Localidades_2010_v1.xlsx\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Use a biblioteca pandas.\nimport pandas as pd\n# Leia o arquivo Excel disponível em: # https://github.com/alexlopespereira/mba_enap/raw/refs/heads/main/data/originais/centroide_municipios/BR_Localidades_2010_v1.xlsx\n# Garanta que a coluna \"CD_GEOCODM,C,20\" seja importada como texto (str).\ndf_xlsx = pd.read_excel('https://github.com/alexlopespereira/mba_enap/raw/refs/heads/main/data/originais/centroide_municipios/BR_Localidades_2010_v1.xlsx', dtype={'CD_GEOCODM,C,20':str})\n# Mostre as 5 primeiras linhas do dataframe.\ndf_xlsx.head()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df_xlsx.columns\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Crie um novo dataframe chamado dfxlsx_geo contendo apenas as colunas:\n# \"CD_GEOCODM,C,20\" → renomeada para \"cod_ibge\"\n# \"NM_CATEGOR,C,50\" → renomeada para \"categoria\"\n# \"LONG,N,24,6\" → renomeada para \"long\"\n# \"LAT,N,24,6\" → renomeada para \"lat\"\n\ndfxlsx_geo = df_xlsx[['CD_GEOCODM,C,20','NM_CATEGOR,C,50','LONG,N,24,6','LAT,N,24,6']].rename(columns={'CD_GEOCODM,C,20':\"cod_ibge\", 'NM_CATEGOR,C,50':\"categoria\", 'LONG,N,24,6':\"long\", 'LAT,N,24,6':\"lat\"})\ndfxlsx_geo.head()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "dfxlsx_geo['categoria'] = dfxlsx_geo['categoria'].str.strip()\ndfxlsx_geo = dfxlsx_geo[dfxlsx_geo['categoria']=='CIDADE']\ndfxlsx_geo.loc[:, 'lat_long'] = dfxlsx_geo['lat'].astype(str) + ',' + dfxlsx_geo['long'].astype(str)\ndfxlsx_geo.head()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Join com a tabela de PIB per capita\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Configurar credenciais locais do BigQuery\nDefina a variável de ambiente `GOOGLE_APPLICATION_CREDENTIALS` com o caminho do arquivo JSON da conta de serviço ou coloque o arquivo `service-account.json` neste diretório antes de executar as consultas.\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\nfrom google.oauth2 import service_account\n\ncredentials = None\n\nservice_account_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\nif service_account_path:\n    candidate = Path(service_account_path)\n    if candidate.exists():\n        credentials = service_account.Credentials.from_service_account_file(candidate)\n        print(f\"Credenciais carregadas de {candidate}\")\n    else:\n        print(f\"⚠ Arquivo informado em GOOGLE_APPLICATION_CREDENTIALS não encontrado: {candidate}\")\n\nif credentials is None:\n    local_candidate = Path(\"service-account.json\")\n    if local_candidate.exists():\n        credentials = service_account.Credentials.from_service_account_file(local_candidate)\n        print(f\"Credenciais carregadas de {local_candidate.resolve()}\")\n    else:\n        print(\"⚠ Nenhum arquivo de credencial localizado. Configure antes de acessar o BigQuery.\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import os\nfrom pandas.io import gbq\n\nif 'credentials' not in globals() or credentials is None:\n    raise RuntimeError(\"Configure as credenciais do BigQuery antes de executar esta célula.\")\n\nproject_id = os.getenv(\"GOOGLE_CLOUD_PROJECT\", \"365846072239\")\nprint(f\"Usando projeto GCP: {project_id}\")\n\nquery = '''\n                        SELECT\n                          d.id_municipio,\n                          d.nome AS nome_municipio,\n                          d.sigla_uf,\n                          pop.ano,\n                          PARSE_DATE('%Y', CAST(pop.ano AS STRING)) AS data_ano,\n                          pop.populacao,\n                          pib.pib,\n                          ROUND(SAFE_DIVIDE(pib.pib, pop.populacao), 2) AS pib_per_capita\n                        FROM `basedosdados.br_bd_diretorios_brasil.municipio` AS d\n\n                        -- junta com população (se não tiver população, fica NULL)\n                        LEFT JOIN `basedosdados.br_ibge_populacao.municipio` AS pop\n                          ON d.id_municipio = pop.id_municipio\n                          AND pop.ano BETWEEN 2002 AND 2018\n\n                        -- junta com pib (se não tiver pib, fica NULL)\n                        LEFT JOIN `basedosdados.br_ibge_pib.municipio` AS pib\n                          ON d.id_municipio = pib.id_municipio\n                        AND pop.ano = pib.ano\n                        AND pop.ano BETWEEN 2002 AND 2018\n                        --LIMIT 100\n                        ;\n                        '''\n\ndf_pibpercapita = gbq.read_gbq(query, project_id=project_id, credentials=credentials)\ndf_pibpercapita.head()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df_pibpercapita['id_municipio'].unique().size\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "dfxlsx_geo['cod_ibge'].unique().size\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "#Algebra relacional: Join. Ou seja, junção de tabelas.\ndf_merge = df_pibpercapita.merge(dfxlsx_geo[['cod_ibge','lat_long']], how='left', left_on='id_municipio', right_on='cod_ibge')\ndf_merge.head()\n\n# renomear pibpercapita para pib_per_capita\ndf_merge.rename(columns={'pibpercapita': 'pib_per_capita'}, inplace=True)\ndf_merge.head()\n\n# formate a PARSE_DATE('%Y', CAST(pop.ano AS STRING)) AS data_ano,\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "del df_merge['cod_ibge']\ndf_merge.head()\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "print(f\"Projeto ativo para BigQuery: {project_id}\")\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "if 'credentials' not in globals() or credentials is None:\n    raise RuntimeError(\"Configure as credenciais do BigQuery antes de executar esta c?lula.\")\n\ndestination_table = \"enapdatasets.pibpercapita\"\ndf_merge.to_gbq(\n    destination_table,\n    project_id=project_id,\n    chunksize=40000,\n    if_exists='replace',\n    credentials=credentials,\n)\nprint(f\"Tabela atualizada no BigQuery: {destination_table}\")\n"
  }
 ]
}